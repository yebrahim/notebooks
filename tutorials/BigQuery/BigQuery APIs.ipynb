{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery APIs\n",
    "\n",
    "Google Cloud Datalab provides an integrated environment for working with Google BigQuery for both adhoc, exploratory work as well as pipeline development. This notebook introduces some of the APIs that Cloud Datalab provides for working with BigQuery.\n",
    "\n",
    "You've already seen the use of `%%bq` in the [Hello BigQuery](Hello BigQuery.ipynb) notebook, and various commands in the [BigQuery Commands](BigQuery Commands.ipynb) notebook. These BigQuery commands are built using the same BigQuery APIs that are available for your own use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the API\n",
    "\n",
    "The Cloud Datalab APIs are provided in the `datalab` Python library, and the BigQuery functionality is contained within the `google.datalab.bigquery` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Data\n",
    "\n",
    "The most important BigQuery-related API is the one that allows you to execute a SQL query. The `google.datalab.bigquery.Query` class provides that functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create and run a SQL query\n",
    "bq.Query('SELECT * FROM `cloud-datalab-samples.httplogs.logs_20140615` LIMIT 3').execute().result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "Let's run the query created above with caching turned off, so we're sure to be able to retrieve metadata, such as bytes processed from resulting query job.\n",
    "\n",
    "For this, we'll need to use a `QueryOutput` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_options = bq.QueryOutput.table(use_cache=False)\n",
    "result = logspreview.execute(output_options=output_options).result()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result object is a `QueryResultsTable` class, and can be enumerated in the same manner a regular Python list, in addition to retrieving metadata about the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspecting the result, and the associated job\n",
    "print result.sql\n",
    "print str(result.length) + ' rows'\n",
    "print str(result.job.bytes_processed) + ' bytes processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the programmatic representation.\n",
    "# Converting the QueryResultsTable to a vanilla list enables viewing the literal data,\n",
    "# as well as side-stepping the HTML rendering seen above.\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Tables\n",
    "\n",
    "In addition to executing queries, BigQuery objects like Datasets, Tables and their Schemas can be accessed programmatically as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = bq.Datasets(project_id = 'cloud-datalab-samples')\n",
    "for ds in datasets:\n",
    "  print ds.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_dataset = list(datasets)[1]\n",
    "tables = sample_dataset.tables()\n",
    "for table in tables:\n",
    "  print '%s (%d rows - %d bytes)' % (table.name.table_id, table.metadata.rows, table.metadata.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('cloud-datalab-samples.httplogs.logs_20140615')\n",
    "fields = map(lambda tsf: tsf.name, table.schema)\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataset (this will be deleted later in the notebook)\n",
    "sample_dataset = bq.Dataset('apisample')\n",
    "sample_dataset.create(friendly_name = 'Sample Dataset', description = 'Created from Sample Notebook')\n",
    "sample_dataset.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To create a table, we also need to create a schema.\n",
    "# Its easiest to create a schema from some existing data, so this\n",
    "# example demonstrates using an example object\n",
    "sample_row = {\n",
    "  'name': 'string value',\n",
    "  'value': 0,\n",
    "  'flag': True\n",
    "}\n",
    "sample_schema = bq.Schema.from_data([sample_row])\n",
    "\n",
    "sample_table = bq.Table(\"apisample.sample_table\").create(schema = sample_schema, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the cell, below, to see the contents of the new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(sample_dataset.tables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clear out sample resources\n",
    "sample_dataset.delete(delete_contents = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking Ahead\n",
    "\n",
    "This notebook covered a small subset of the APIs. Subsequent notebooks cover additional capabilities, such as importing and exporting data into and from BigQuery tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
